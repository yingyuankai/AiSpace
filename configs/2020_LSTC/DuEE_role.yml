includes:
#  - "../pretrain/bert_wwm.yml"
  - "../pretrain/ernie.yml"

model_name: bert_for_role_ner

model_attributes:
    hidden_dropout_prob: 0.5
    initializer_range: 0.02
    hidden_size: 1024

training:
  learning_rate: 1e-4
  max_epochs: 30
  batch_size: 32
  callbacks:
    # callback name
    early_stopping:
      switch: true
      config:
        patience: 2

dataset:
  name: "lstc_2020/DuEE_role"
  data_dir: "./data"
  transformer: "lstc_2020/DuEE_role"

  source:
    train: "train"
    validation: "validation[:50%]"
    test: "validation[-50%:]"

  tokenizer:
    max_len: 120

  inputs:
    - name: input_ids
      column: input_ids
      type: LIST_OF_INT
      max_len: 120
    - name: token_type_ids
      column: token_type_ids
      type: LIST_OF_INT
      max_len: 120
    - name: attention_mask
      column: attention_mask
      type: LIST_OF_INT
      max_len: 120
    - name: position_ids
      column: position_ids
      type: LIST_OF_INT
      max_len: 120
    - name: label_mask
      column: label_mask
      type: LIST_OF_INT
      max_len: 243

  outputs:
    - name: output_1
      column: labels
      type: LIST_OF_CLASSLABEL
      task: NER
      num: 0
      labels:
        url: "https://ai.baidu.com/file/9C92719AF96D4DDB96477BFBE1435262"
        name: "duee_role_ner_labels"
      loss:
        name: myself_crf_loss
#        name: sparse_categorical_crossentropy
#        config:
#          from_logits: true
      metrics:
        - name: sparse_categorical_accuracy
        - name: sparse_f1_score
          config:
            num_classes: 243
            average: "macro"
            name: "macro_f1"

pretrained:
#    name: chinese_roberta_wwm_ext
    name: ERNIE_1.0_max-len-512
    init_from_pretrained: true


