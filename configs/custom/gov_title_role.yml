includes:
  - "../pretrain/ernie.yml"

#model_name: bert_for_ner_with_title_status
model_name: bert_for_ner

model_attributes:
    hidden_dropout_prob: 0.5
    initializer_range: 0.02
    hidden_size: 1024

training:
#  policy:
#    name: "k-fold"
#    config:
#      k: 5
  learning_rate: 1e-5
  max_epochs: 30
  batch_size: 8

#  optimizer:
#    name: adam

  callbacks:
    # callback name
    early_stopping:
      switch: true
      config:
        patience: 2
    lr_finder:
      switch: false
      config:
        end_lr: 1e-4

  optimizer_wrappers:
    swa:
      switch: false
      config:
        start_epoch: 5

dataset:
  name: gov_title/role
  data_dir: "./data"
  data_path: "./data/downloads/extracted/gov_title/gov_title_event.txt"
  transformer: "gov_title/role"

  source:
    train: "train[:80%]"
    validation: "train[80%:90%]"
    test: "train[-10%:]"

  tokenizer:
    max_len: 512

  inputs:
    - name: input_ids
      column: input_ids
      type: LIST_OF_INT
      max_len: 512
    - name: token_type_ids
      column: token_type_ids
      type: LIST_OF_INT
      max_len: 512
    - name: attention_mask
      column: attention_mask
      type: LIST_OF_INT
      max_len: 512
    - name: position_ids
      column: position_ids
      type: LIST_OF_INT
      max_len: 512

  outputs:
    - name: output_1
      column: label
      type: LIST_OF_CLASSLABEL
      task: NER
      num: 11
      labels: ["O", "B-PERSON", "I-PERSON", "B-ORGANIZATION", "I-ORGANIZATION",
               "B-LOCATION", "I-LOCATION", "B-START_DATE", "I-START_DATE", "B-END_DATE", "I-END_DATE"]
      loss:
        name: myself_crf_loss
#        name: sparse_categorical_crossentropy
#        config:
#          from_logits: true
      metrics:
        - name: sparse_categorical_accuracy
        - name: sparse_f1_score
          config:
            name: "macro_f1"
            num_classes: 11
            average: "macro"

pretrained:
    name: ERNIE_1.0_max-len-512
    init_from_pretrained: true
#    config:
#      layers:
#        start: 0
#        end: 4
#        step: 1


